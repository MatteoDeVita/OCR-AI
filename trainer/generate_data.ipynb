{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_FILE_PATH = \"./data.txt\"\n",
    "IMAGE_HEIGHT = 64\n",
    "BATCH_SIZE = 16\n",
    "N_NEURONS=2048\n",
    "LEARNING_RATE=0.00001\n",
    "CP_PATH = \"./training/cp-{epoch:04d}.ckpt\"\n",
    "AUTOTUNE = tf.data.AUTOTUNE # Let tf decide the best tunning algos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3983bc7f8ee841feb22abdc65c077252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/581581 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e733ca027e2347e187acc890f225859e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8919273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80a214d93ca43e1bdb302ffef5a6616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9500854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def filter_data(data, len_range, max_space):\n",
    "    if data[\"label\"] is None:\n",
    "        return False\n",
    "    if len(data[\"label\"]) < len_range[0] or len(data[\"label\"]) > len_range[1]:\n",
    "        return False\n",
    "    if data[\"label\"].count(' ') > max_space:\n",
    "        return False\n",
    "    if data[\"label\"].isascii() == False:\n",
    "        return False    \n",
    "    for char in \"\\n\\r\\xad\\xa0\":\n",
    "        if char in data[\"label\"]:\n",
    "            return False\n",
    "    # try:\n",
    "    #     image = Image.open(data[\"image_path\"])\n",
    "    #     image.verify()\n",
    "    #     if image.format != \"JPEG\" and image.format != \"PNG\":\n",
    "    #         print(\"not a valid format\")\n",
    "    #         return False\n",
    "    # except:\n",
    "    #     print(\"invalid image or path\")\n",
    "    #     return False\n",
    "\n",
    "    # if os.path.exists(data[\"image_path\"]) == False:\n",
    "    #     return False\n",
    "    return True\n",
    "\n",
    "def get_dataset(\n",
    "        data_file_dir,\n",
    "        multi_fonts_dir,\n",
    "        mjsynth_dir,\n",
    "        max_multi_fonts_len,\n",
    "        max_mjsynth_len,\n",
    "        len_range,\n",
    "        max_space\n",
    "):\n",
    "    dataset = []\n",
    "    data_file = open(os.path.join(data_file_dir, \"data.txt\"), \"a+\")\n",
    "    multi_fonts_data = open(os.path.join(multi_fonts_dir, 'data.txt')).readlines()\n",
    "    mjsynth_data = open(os.path.join(mjsynth_dir, \"imlist.txt\")).readlines()\n",
    "    random.shuffle(multi_fonts_data)\n",
    "    random.shuffle(mjsynth_data)\n",
    "    multi_fonts_data = multi_fonts_data[:max_multi_fonts_len]\n",
    "    mjsynth_data = mjsynth_data[:max_mjsynth_len]\n",
    "    for line in tqdm(multi_fonts_data):\n",
    "        splitted_line = line.split(' ', 1)\n",
    "        label = splitted_line[1].split('\\n')[0]\n",
    "        dataset.append({\"image_path\": os.path.join(multi_fonts_dir, splitted_line[0]), \"label\": label})\n",
    "    for image_name in tqdm(mjsynth_data):\n",
    "        image_name = image_name.split('\\n')[0]\n",
    "        label = image_name.split('/')[-1].split('_')[1]\n",
    "        dataset.append({\"image_path\": os.path.join(mjsynth_dir, image_name), \"label\": label})\n",
    "    random.shuffle(dataset)\n",
    "    dataset = list(filter(lambda data: filter_data(data, len_range, max_space), tqdm(dataset)))\n",
    "\n",
    "    # for data in tqdm(dataset):\n",
    "    #     data_file.write(f\"{data['image_path']} {data['label']}\\n\")\n",
    "    data_file.close()\n",
    "    return dataset\n",
    "\n",
    "def split_dataset(dataset, training_i, validation_i):\n",
    "    train_ds = dataset[:int(training_i*len(dataset))] #98% of the whole dataset is train dataset\n",
    "    validation_ds = dataset[int(training_i*len(dataset)):int(validation_i*len(dataset))] #1% is  validation dataset\n",
    "    test_ds = dataset[int(validation_i*len(dataset)):] #1% is test dataset\n",
    "    return train_ds, validation_ds, test_ds\n",
    "\n",
    "\n",
    "def distortion_free_resize(image, img_size):\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "\n",
    "    # Check tha amount of padding needed to be done.\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    # Only necessary if you want to do same amount of padding on both sides.\n",
    "    if pad_height % 2 != 0:\n",
    "        height = pad_height // 2\n",
    "        pad_height_top = height + 1\n",
    "        pad_height_bottom = height\n",
    "    else:\n",
    "        pad_height_top = pad_height_bottom = pad_height // 2\n",
    "\n",
    "    if pad_width % 2 != 0:\n",
    "        width = pad_width // 2\n",
    "        pad_width_left = width + 1\n",
    "        pad_width_right = width\n",
    "    else:\n",
    "        pad_width_left = pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(\n",
    "        image,\n",
    "        paddings=[\n",
    "            [pad_height_top, pad_height_bottom],\n",
    "            [pad_width_left, pad_width_right],\n",
    "            [0, 0],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image\n",
    "\n",
    "def vectorize_label(label, max_len, char_to_num):\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = max_len - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=99) #Padding token = 99\n",
    "    return label\n",
    "\n",
    "def preprocess_image(image_path, img_size):\n",
    "    image = tf.io.read_file(image_path) # Open file with tf\n",
    "    image = tf.image.decode_png(image, channels=1) # transform to matrix of gray scale value\n",
    "    image = distortion_free_resize(image, img_size) # Distort image\n",
    "    image = tf.cast(image, tf.float32) / 255.0 # Transform image to data into matrix of gray scale float32 values in range [0, 1]\n",
    "    return image\n",
    "\n",
    "def process_images_labels(image_path, label, img_size, max_len, char_to_num):\n",
    "    image = preprocess_image(image_path, img_size)\n",
    "    label = vectorize_label(label, max_len, char_to_num)\n",
    "    return {\"image\": image, \"label\": label}\n",
    "\n",
    "def prepare_dataset(image_paths, labels, batch_size, img_size, max_len, char_to_num):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (image_paths, labels)\n",
    "    ).map(\n",
    "        lambda image_path, label: process_images_labels(image_path, label, img_size, max_len, char_to_num), num_parallel_calls=AUTOTUNE\n",
    "    ).batch(batch_size)\n",
    "\n",
    "dataset = get_dataset(\n",
    "    \"./\",\n",
    "    \"../datasets/multi-fonts-generated-text/\",\n",
    "    \"../datasets/mjsynth/mnt/ramdisk/max/90kDICT32px/\",\n",
    "    1_000_000_000,\n",
    "    1_000_000_000,\n",
    "    len_range=(3, 32),\n",
    "    max_space=3\n",
    ")\n",
    "labels = list(map(lambda data: data[\"label\"].replace('|',  '\\n'), dataset))\n",
    "max_len = len(max(labels, key=len))\n",
    "characters = sorted(list(set(char for label in labels for char in label)))\n",
    "train_ds, validation_ds, test_ds = split_dataset(dataset, 0.98, 0.99)\n",
    "train_ds, validation_ds, test_ds = split_dataset(dataset, 0.98, 0.99)\n",
    "char_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n",
    "num_to_char = StringLookup(vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True)\n",
    "# train_ds = prepare_dataset(\n",
    "#     list(map(lambda data: data[\"image_path\"], train_ds)),\n",
    "#     list(map(lambda data: data[\"label\"], train_ds)),\n",
    "#     BATCH_SIZE,\n",
    "#     (IMAGE_HEIGHT * 4, IMAGE_HEIGHT),\n",
    "#     max_len,\n",
    "#     char_to_num\n",
    "# )\n",
    "# validation_ds = prepare_dataset(\n",
    "#     list(map(lambda data: data[\"image_path\"], validation_ds)),\n",
    "#     list(map(lambda data: data[\"label\"], validation_ds)),\n",
    "#     BATCH_SIZE,\n",
    "#     (IMAGE_HEIGHT * 4, IMAGE_HEIGHT),\n",
    "#     max_len,\n",
    "#     char_to_num\n",
    "# )\n",
    "test_ds = prepare_dataset(\n",
    "    list(map(lambda data: data[\"image_path\"], test_ds)),\n",
    "    list(map(lambda data: data[\"label\"], test_ds)),\n",
    "    BATCH_SIZE,\n",
    "    (IMAGE_HEIGHT * 4, IMAGE_HEIGHT),\n",
    "    max_len,\n",
    "    char_to_num\n",
    ")\n",
    "\n",
    "# train_ds.save(\"./train_ds\")\n",
    "# validation_ds.save(\"./validation_ds\")\n",
    "test_ds.save(\"./test_ds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1867\n"
     ]
    }
   ],
   "source": [
    "#### Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
